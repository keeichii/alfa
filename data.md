# Описание RAG Pipeline: Архитектура и Реализация

## Обзор системы

RAG-система для поиска релевантных документов по пользовательским вопросам с максимизацией метрики Hit@5. Система использует гибридный подход (dense + sparse retrieval) с двухстадийным реранкингом.

## Архитектура пайплайна

```
CSV (websites) 
  ↓ [ingest]
corpus.jsonl (title + text)
  ↓ [chunk]
chunks.jsonl (семантические чанки)
  ↓ [index]
[FAISS Index]  [BM25 Index]
  ↓         ↓
[Hybrid Retriever] (weighted/RRF)
  ↓
[Cross-Encoder Reranker]
  ↓
[Top-5 web_ids] → submit.csv
```

## Компоненты системы

### 1. Предобработка данных

#### 1.1 Ingest (`src/ingest.py`)

**Функция:** Преобразование CSV в структурированный корпус JSONL

**Процесс:**
1. Чтение `websites_updated.csv` с увеличенным лимитом поля
2. Нормализация UTF-8 (NFKC)
3. Удаление управляющих символов (кроме \n, \t, \r)
4. Обработка таблиц (сохранение структуры)
5. Валидация качества документов
6. Формирование `corpus.jsonl` с полями:
   - `id`: web_id
   - `title`: очищенный заголовок
   - `text`: очищенный текст
   - `contents`: `title + "\n" + text` (для FlashRAG)

**Алгоритм:** O(n) по времени, O(n) по памяти

**Особенности:**
- Автоматическое извлечение заголовка из первого предложения, если title пуст
- Обнаружение и фильтрация документов с избыточными повторами
- Детальное логирование причин пропуска документов

#### 1.2 Chunking (`src/chunker.py`, `src/semantic_chunker.py`)

**Функция:** Разбиение документов на семантически целостные чанки

**Два режима:**

**A. Токен-базированный чанкинг** (`DocumentChunker`)
- Использует `chonkie.TokenChunker`
- Размер: ~600 токенов, overlap: 150
- Объединение коротких параграфов

**B. Семантико-структурный чанкинг** (`SemanticChunker`) — **рекомендуется**
- Обнаружение заголовков (markdown `#`, ALL CAPS, строки с `:`)
- Сохранение структуры таблиц
- Разбиение по семантическим границам (секции, абзацы, таблицы)
- Динамический размер: 400-800 токенов с overlap 10-20%

**Алгоритм:** O(n * m) по времени, где n — документы, m — средние токены

**Результат:** `chunks.jsonl` с полями:
- `id`: `{doc_id}_{segment_idx}_{chunk_idx}`
- `doc_id`: web_id исходного документа
- `title`: заголовок (префикс)
- `text`: текст чанка
- `contents`: `title + "\n" + text`
- `has_table`: флаг наличия таблицы

### 2. Обработка таблиц (`src/table_processor.py`)

**Функция:** Сохранение структуры таблиц для банковского домена

**Обнаружение таблиц:**
- Markdown формат: `| Колонка 1 | Колонка 2 |`
- Tab-separated значения
- Space-aligned колонки

**Обработка:**
- Нормализация разделителей
- Сохранение заголовков колонок
- Плоский текст с разделителями для индексации

**Пример:**
```
Валюта | Покупка | Продажа
USD    | 77      | 80.4
```
→ Сохраняется как структурированный текст

### 3. Обработка числовых значений (`src/table_processor.py`)

**Функция:** Улучшение поиска для запросов с числами, валютами, курсами

**Извлечение:**
- Валюты: `1000 руб.`, `$100`, `100 EUR`
- Проценты: `5%`, `10.5%`
- Курсы: `курс 77.5`, `ставка 10%`
- Большие числа: `1 000 000`
- Даты: `01.01.2024`

**Улучшение запросов:**
- `enhance_query_for_numerics()` добавляет вариации
- Пример: `"1000 руб"` → `"1000 руб 1000.0 1000,0"`

**Проверка соответствия:**
- `check_numeric_matching()` проверяет наличие числовых значений в ретривленных чанках

### 4. Построение индексов

#### 4.1 FAISS Index (`scripts/build_index_dense.py`)

**Использует:** FlashRAG `Index_Builder`

**Процесс:**
1. Загрузка `chunks.jsonl`
2. Векторизация через sentence-transformers
3. Построение FAISS индекса (Flat для MVP, IVF для больших корпусов)
4. Сохранение метаданных: `faiss_meta.json` с `chunk_ids` и `doc_ids`

**Модель:** `intfloat/multilingual-e5-base` (настраивается)

**Результат:**
- `indexes/faiss/{model}_{type}.index` — FAISS индекс
- `indexes/faiss/faiss_meta.json` — метаданные

#### 4.2 BM25 Index (`scripts/build_index_bm25.py`)

**Использует:** FlashRAG `Index_Builder` с backend `bm25s`

**Процесс:**
1. Загрузка `chunks.jsonl`
2. Токенизация с учётом русского языка
3. Построение BM25 индекса
4. Копирование `chunks.jsonl` для ретривера

**Результат:**
- `indexes/bm25/bm25/` — индекс bm25s
- `indexes/bm25/chunks.jsonl` — копия чанков

### 5. Гибридный ретривер (`src/retriever.py`)

**Функция:** Объединение dense (FAISS) и sparse (BM25) поиска

#### 5.1 Dense Retrieval

**Процесс:**
1. Кодирование запроса через sentence-transformers
2. Поиск в FAISS индексе (inner product)
3. Получение top-K кандидатов с скорингами

**Особенности:**
- Нормализация эмбеддингов
- Поддержка batch-обработки

#### 5.2 Sparse Retrieval (BM25)

**Процесс:**
1. Улучшение запроса для числовых значений (если включено)
2. Токенизация через bm25s
3. Поиск в BM25 индексе
4. Получение top-K кандидатов с BM25 скорингами

**Особенности:**
- Усиление для точных совпадений
- Специальная обработка для банковских терминов

#### 5.3 Hybrid Fusion

**Два метода объединения:**

**A. Weighted Sum (по умолчанию)**
```
score = w_dense * normalize(dense_score) + w_bm25 * normalize(bm25_score)
```
- `w_dense = 0.6`, `w_bm25 = 0.4` (настраивается)
- Требует нормализации скорингов

**B. RRF (Reciprocal Rank Fusion)**
```
score = 1/(60 + rank_dense) + 1/(60 + rank_bm25)
```
- Не требует нормализации
- Устойчив к различиям в распределениях скорингов
- Лучше работает при разных масштабах

**Алгоритм:** O(k * log(n)) для FAISS, O(k) для BM25

### 6. Реранкер (`src/reranker.py`)

**Функция:** Переупорядочивание кандидатов по истинной релевантности

**Процесс:**
1. Приём top-K кандидатов от гибридного ретривера
2. Оценка пар (query, document) через cross-encoder
3. Сортировка по rerank scores
4. Возврат top-5 для сабмита

**Модель:** `cross-encoder/ms-marco-MiniLM-L-12-v2` (настраивается)

**Особенности:**
- Batch-обработка для эффективности
- Сохранение оригинальных скорингов для анализа

**Алгоритм:** O(n * m), где n — кандидаты, m — forward pass модели

### 7. Оценка метрик (`src/evaluator.py`)

**Функция:** Вычисление метрик качества ретривера

#### 7.1 Hit@K

**Определение:** Доля вопросов, для которых среди первых K результатов есть хотя бы один релевантный документ.

**Формула:**
```
Hit@K = (1/|Q|) * Σ hit@K(q)
где hit@K(q) = 1, если {r1, ..., rK} ∩ Gq ≠ ∅, иначе 0
```

**Целевая метрика:** Hit@5 ≥ 0.70

#### 7.2 Recall@K

**Определение:** Средняя доля найденных релевантных документов в топ-K.

**Формула:**
```
Recall@K = (1/|Q|) * Σ (|{r1, ..., rK} ∩ Gq| / |Gq|)
```

#### 7.3 MRR (Mean Reciprocal Rank)

**Определение:** Средний обратный ранг первого релевантного документа.

**Формула:**
```
MRR = (1/|Q|) * Σ (1 / rank_first_relevant(q))
```

#### 7.4 NDCG@K (Normalized Discounted Cumulative Gain)

**Определение:** Нормализованный дисконтированный кумулятивный выигрыш.

**Формула:**
```
NDCG@K = DCG@K / IDCG@K
где DCG@K = Σ (relevance_i / log2(rank_i + 1))
```

### 8. Логирование провалов (`src/failure_logger.py`)

**Функция:** Детальный анализ случаев, когда релевантные документы не попали в топ-K

**Типы провалов:**
1. **No relevant in top-K:** Релевантные документы не в топ-K
2. **Relevant in candidates but not in top-K:** Релевантные в кандидатах, но не поднялись реранкером
3. **Missing numerics:** Числовые значения из запроса не найдены в чанках

**Информация в логах:**
- Query и извлеченные числовые значения
- Топ-K web_ids и релевантные web_ids
- Наличие релевантных в полном списке кандидатов
- Автоматические предложения по улучшению

**Использование:**
- Анализ паттернов провалов
- Настройка параметров на основе данных
- Выявление проблемных типов запросов

## Поток данных

### Входные данные

**`data/raw/questions_clean.csv`:**
```csv
q_id,query
1,Номер счета
2,Где узнать бик и счёт
```

**`data/raw/websites_updated.csv`:**
```csv
web_id,url,kind,title,text
1,https://...,html,Заголовок,Текст страницы...
```

### Промежуточные данные

**`data/processed/corpus.jsonl`:**
```json
{"id": "1", "title": "Заголовок", "text": "Текст...", "contents": "Заголовок\nТекст..."}
```

**`data/processed/chunks.jsonl`:**
```json
{"id": "1_0_0", "doc_id": "1", "title": "Заголовок", "text": "Чанк текста...", "contents": "Заголовок\nЧанк текста...", "has_table": false}
```

### Индексы

**`indexes/faiss/`:**
- `{model}_{type}.index` — FAISS индекс
- `faiss_meta.json` — метаданные (chunk_ids, doc_ids)

**`indexes/bm25/bm25/`:**
- Файлы индекса bm25s
- `chunks.jsonl` — копия чанков

### Выходные данные

**`outputs/submits/submit_*.csv`:**
```csv
q_id,web_list
1,"[123, 456, 789, 101, 112]"
```

**`outputs/reports/report_*.json`:**
```json
{
  "timestamp": "20250112_120000",
  "config": {...},
  "metrics": {
    "hit@5": 0.75,
    "recall@5": 0.60,
    "mrr": 0.65,
    "ndcg@5": 0.70
  },
  "failure_summary": {...}
}
```

**`outputs/logs/candidates_*.jsonl`:**
```json
{"q_id": 1, "query": "...", "stage": "before_rerank", "candidates": [...]}
{"q_id": 1, "query": "...", "stage": "after_rerank", "candidates": [...]}
```

**`outputs/logs/failures_*.json`:**
```json
{
  "total_failures": 25,
  "failures": [
    {
      "q_id": 123,
      "query": "Курс доллара 77",
      "failure_type": "no_relevant_in_topk",
      "query_numerics": [{"value": "77", "type": "rate"}],
      "suggestions": [...]
    }
  ]
}
```

## Алгоритмическая сложность

### Предобработка

- **Ingest:** O(n) времени, O(n) памяти
- **Chunking:** O(n * m) времени, O(n * k) памяти
  - n — документы
  - m — средние токены на документ
  - k — средние чанки на документ

### Ретрив

- **Dense (FAISS):** O(k * log(n)) времени
- **Sparse (BM25):** O(k) времени
- **Hybrid fusion:** O(k) времени
- **Reranking:** O(k * m) времени, где m — forward pass модели

### Общая сложность

Для одного запроса: O(k * log(n) + k * m)
- k — количество кандидатов (50-75)
- n — размер индекса (тысячи-миллионы)
- m — сложность модели реранкера

## Обоснование выбора алгоритмов

### 1. Гибридный ретрив (Dense + Sparse)

**Почему:**
- Dense поиск (FAISS) ловит семантические соответствия
- Sparse поиск (BM25) ловит точные совпадения ключевых слов
- Комбинация максимизирует recall и снижает риск пропуска релевантных документов

**Альтернативы:**
- Только dense: может пропускать точные совпадения
- Только sparse: может пропускать семантически похожие документы

### 2. Двухстадийный ретрив (Retrieve → Rerank)

**Почему:**
- Первая стадия (гибридный ретрив) обеспечивает высокий recall
- Вторая стадия (cross-encoder) обеспечивает точное ранжирование
- Cross-encoder точнее, но медленнее — применяем только к top-K

**Альтернативы:**
- Только ретрив: менее точное ранжирование
- Только cross-encoder: слишком медленно для больших корпусов

### 3. Семантико-структурное чанкование

**Почему:**
- Сохраняет семантическую целостность (таблицы не разрываются)
- Улучшает качество ретрива за счёт сохранения контекста
- Критично для банковского домена (таблицы тарифов, курсов)

**Альтернативы:**
- Простое токен-базированное: может разрывать таблицы и секции

### 4. RRF vs Weighted Sum

**RRF преимущества:**
- Не требует нормализации скорингов
- Устойчив к различиям в распределениях
- Проще настраивать

**Weighted Sum преимущества:**
- Более гибкий контроль весов
- Может учитывать уверенность моделей

**Рекомендация:** Попробовать оба метода и выбрать лучший на валидации

## Особенности для банковского домена

### 1. Обработка таблиц

- Таблицы тарифов/курсов сохраняют структуру
- Заголовки колонок остаются с данными
- Плоский текст с разделителями для лучшей индексации

### 2. Числовые значения

- Усиленное сопоставление валют, процентов, курсов
- Улучшение запросов с числовыми значениями
- Проверка наличия числовых значений в ретривленных чанках

### 3. Точные термины

- BM25 усилен для банковской терминологии
- Специальная обработка для тарифных терминов

## Воспроизводимость

### Конфигурация

Все параметры сохраняются в:
- `configs/base.yaml` — параметры пайплайна
- `configs/models.yaml` — модели и их параметры

### Версионирование

- Каждый прогон создаёт timestamped артефакты
- Отчёты содержат полную конфигурацию
- Логи позволяют воспроизвести результаты

### Репродукция

Для воспроизведения результата:
1. Использовать те же конфиги
2. Использовать те же версии моделей
3. Использовать те же данные

## Оптимизация и настройка

### Параметры для настройки

1. **Размер чанка:** 500-800 токенов (по умолчанию 600)
2. **Overlap:** 100-200 токенов (по умолчанию 150)
3. **Веса гибрида:** `w_dense` и `w_bm25` (по умолчанию 0.6 и 0.4)
4. **k_retrieve:** количество кандидатов до реранка (по умолчанию 50)
5. **Fusion method:** "weighted" или "rrf"
6. **Модели:** выбор embedding и reranker моделей

### Рекомендации

- Для больших корпусов (>100K чанков): используйте IVF индексы FAISS
- Для многоязычных данных: используйте multilingual модели (E5, BGE)
- Для скорости: уменьшите `k_retrieve` или используйте более быстрый reranker
- Для качества: увеличьте `k_retrieve` и используйте более точный reranker

## Метрики и оценка

### Целевая метрика: Hit@5

**Цель:** ≥ 0.70 на публичной части

**Интерпретация:** 70% вопросов имеют хотя бы один релевантный документ в топ-5

### Диагностические метрики

- **Recall@K:** Показывает, какая доля релевантных документов найдена
- **MRR:** Показывает качество ранжирования первого релевантного документа
- **NDCG@K:** Показывает качество ранжирования с учётом позиций

### Анализ провалов

Логи провалов (`outputs/logs/failures_*.json`) содержат:
- Типы провалов
- Извлеченные числовые значения
- Предложения по улучшению
- Статистику по категориям

## Заключение

Система реализует полный пайплайн RAG с продвинутыми улучшениями:
- ✅ Семантико-структурное чанкование
- ✅ Обработка таблиц и числовых значений
- ✅ Гибридный ретрив с RRF
- ✅ Cross-encoder реранкинг
- ✅ Детальное логирование и анализ
- ✅ Полная воспроизводимость

Готова к использованию и оптимизации для максимизации Hit@5!

